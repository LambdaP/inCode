<!-- So if I have a `(Reader Int) Bool`, I have a `Bool` that "lives" in the -->
<!-- `Reader Int` world --- it is an ephemeral `Bool` that does not yet exist; it -->
<!-- exists in the world of future values, awaiting an `Int`.  A `(Reader Int) -->
<!-- Bool` is a future `Bool`; a *waiting* `Bool`. -->

#### A real executable

In a real executable, we might want to print that `Int` to standard output. Well,
luckily, we have `print :: Int -> IO ()`[^print], which takes an `Int` and
produces a future `()`.[^unit]  But in that process of producing that `()`, it
sneaks in computer instructions (assembly/C code) to print out that given
integer to standard output.  We like to use `print` not because of what it
computes, but rather because of the side effects it sneaks into its
computation process.  (Remember, these side effects don't actually happen
until it is computed, in the future)

[^print]: the real type signature of  `print` takes all showable things, not
just `Int`.

[^unit]: `()`, pronounced "unit", is basically the "boring type", which only
has one value --- `()`.  `IO ()` is loosely comparable to a "void"
function/computation in other languages, which "return nothing".

We can apply `print` to an `IO Int` by using `(=<<)`, of course:

~~~haskell
print       :: Int -> IO ()
(=<<) print :: IO Int -> IO ()
~~~

Putting it all together, we can write a compilable Haskell executable:

~~~haskell
!!!inside/io.hs "main ::" inside-my-world
~~~

What is happening?

1.  `getLine` is a future `String`.
2.  `wc =<< getLine` is a future `Int`.
3.  `print =<< wc =<< getLine` is a future `()`, which prints out that future
    `Int` in the process.

When you use ghc to compile this `IO ()`, it'll create a binary executable.

This executable, when executed:

1.  Gets a line from standard input.
2.  Gets the line count from the given filename.
3.  Prints that line count.


<!-- An important distinction between `IO` and the other worlds we have looked at -->
<!-- is that there is no way to "exit" the world of `IO` within Haskell.  That is, -->
<!-- there is no meaningful `IO a -> a`. -->

<!-- If you think about it for a while, it kind of makes sense.  If `IO a` is -->
<!-- assembly code for a computer...the only thing that can "get" that `a` is the -->
<!-- computer itself --- by shifting those registers, ticking that program clock, -->
<!-- reading from IO... -->

<!-- Remember, *a Haskell program can only "evaluate"* expressions, *not "execute"* -->
<!-- them.  The execution is the computer's job.  When you compile a Haskell -->
<!-- program, the compiler takes whatever `IO ()` is named `main` in your program, -->
<!-- *evaluates* it, and compiles it into a binary. Then you, the computer user, -->
<!-- can *execute* that binary like any other binary (compiled from C or -->
<!-- whatever).[^iopure]  Because you can never "exit" `IO` in your Haskell code, -->
<!-- this makes `IO` an extreme version of the worlds we mentioned before; in the -->
<!-- others, we could "exit" the world if we really wanted to.  We only used `fmap` -->
<!-- and `(=<<)` because it provided for beautiful abstractions. -->

<!-- [^iopure]: I actually wrote a whole [blog post][iopurepost] on this topic :) -->

<!-- [iopurepost]: http://blog.jle.im/entry/the-compromiseless-reconciliation-of-i-o-and-purity -->

<!-- Because of this, if it weren't for Functor and Monad, it would be extremely -->
<!-- hard to do *anything* useful with `IO`!  We literally can't pass an `IO a` -->
<!-- into *any* normal function.  We need Functor and Monad for us to *ever* work -->
<!-- at all with our "future values" with normal functions! -->

<!-- #### Anything Useful -->


<!-- Let's say we had `headReader`, which is a machine that is awaiting a list in -->
<!-- order to produce a value (the head of that given list).  We can also think of -->
<!-- this as a value that has yet to be calculated --- and that is awaiting for a -->
<!-- list in order to be realized. Let's say that we want to make `headEvenReader`, -->
<!-- which is a `Bool` that is waiting for a list in order to be realized, and that -->
<!-- `Bool` comes from whether or not the first element is even. -->

<!-- We have a `(Reader [Int]) Int`, and we have `even :: Int -> Bool` that tells -->
<!-- if an integer is even. -->

<!-- Well, we can use our normal function inside our `Reader [Int]` world! -->

<!-- ~~~haskell -->
<!-- headEvenReader :: (Reader [Int]) Int -->
<!-- headEvenReader = fmap even headReader -->
<!-- ~~~ -->

<!-- ~~~haskell -->
<!-- λ: runReader headReader [2,3,4] -->
<!-- 2 -->
<!-- λ: runReader headEvenReader [2,3,4] -->
<!-- True -->
<!-- λ: runReader headEvenReader [5,3,4] -->
<!-- False -->
<!-- ~~~ -->

<!-- The *semantics* of `fmap` for `Reader [Int]` is that it applies that function -->
<!-- to the future value, once it has been obtained.  That is, once you get a `Int` -->
<!-- from the `[Int]`, it applies the function `even` to that `Int` before finally -->
<!-- popping it out. -->

<!-- Let's look at an `a -> (Reader r) b`: -->

<!-- ~~~haskell -->
<!-- isLongerThan :: Int -> (Reader [x]) Bool -->
<!-- isLongerThan n = fmap (> n) lengthReader -->
<!-- ~~~ -->

<!-- where `isLongerThan 2` is a `Bool` living in the world of awaiting --- it is -->
<!-- awaiting an `[x]` before it can be realized.  When that `[x]` finally comes -->
<!-- in, the `Bool` is whether or not the length of the list is greater than `2`. -->

<!-- We can "apply" `isLongerThan` to our `headReader`!  So that we know if the -->
<!-- head of the list is a number that is smaller than or equal to the length of -->
<!-- the whole list. -->

<!-- ~~~haskell -->
<!-- headIsLongerThan :: (Reader [Int]) Bool -->
<!-- headIsLongerThan = isLongerThan =<< headReader -->
<!-- ~~~ -->

<!-- Remember, `isLongerThan` is an `Int -> (Reader [Int]) Bool`, and `headReader` -->
<!-- is a `(Reader [Int]) Int`.  We can turn our `Int -> (Reader [Int]) Bool` into -->
<!-- a `(Reader [Int]) Int -> (Reader [Int]) Bool` using `(=<<)`! -->

<!-- And just like that, we can now work with the world of awaiting as if it were -->
<!-- no biggie. -->




<aside>
    ###### Aside

Between `Functor` and `Monad`, there is another useful typeclass called
`Applicative` that lets you "merge" values in worlds together.

That is, if you had a matchmaking algorithm that calculates the compatibility
of two `Person`s, `compatibility :: Person -> Person -> Double`.

`compatiblity` can be described as a function that takes two `Person`s and
"squashes" them into one `Double`.

What if we wanted a `compatibiliy` that takes two `Maybe Person`s and
"squashes" them into one `Maybe Double`?

For that, we have the "squashing" typeclass, `Applicative`, which allows us
two arbitrarily combine two or three or as many `Maybe a`s as we want!
(Because `Maybe` implements/instances `Applicative`)

In our case, we can use `liftA2`, which does exactly what we wanted for
`compatibility`: `liftA2 :: (a -> b -> c) -> (Maybe a -> Maybe b -> Maybe c)`.

~~~haskell
λ: personFromId 144
Just John
λ: personFromId 15
Just Sara
λ: personFromId 73
Nothing
λ: compatibility John Sara
82.3
λ: (liftA2 compatibility) (personFromId 144) (personFromId 15)
Just 82.3
λ: (liftA2 compatibility) (personFromId 144) (personFromId 73)
Nothing
~~~

In the last case, obviously there is no value of compatibility between a
person that exists and a person that doesn't exist.

The `Applicative` typeclass is a rather powerful and amazing typeclass, and
there is a [great tutorial on it here][adit] on all of its nuances.

[adit]: http://adit.io/posts/2013-04-17-functors,_applicatives,_and_monads_in_pictures.html

The main *point* is that `Applicative` lets us take *two or more* "values" in
our worlds, and combine them into one value, all staying "inside" the world.
And staying "inside the world" is what this post is all about, isn't it?

For the purposes of this article, `liftA2` and
`liftA3` are the most interesting; they sort of "fill out" that list of normal
functions that we have ways to turn "into" our world-y functions: `a -> b`, `a
-> Maybe b`, and now `a -> b -> c` and `a -> b -> c -> d`!
</aside>
### The world of state-modifying awaiters

`Reader r` is admittedly a pretty boring world (and you probably could have
guessed that a `(Reader r) a` is basically just an `r -> a` in disguise
somehow).  But let's try another world, `State s`.  `State s` is a lot like
`Reader s` --- it is the world of values not yet existing, but awaiting an `s`
to be realized.  Only, in `State s`, the "realization process"
maims/affects/perturbs/modifies `s`.

So `(State Int) Bool` is a `Bool` that does not yet exist, and is awaiting an
`Int` in order to be realized.  But in the process of realizing itself, it
changes the `Int`.


<!-- Merging Worlds -->
<!-- -------------- -->

<!-- So with `Functor`, if we have a `Maybe a`, we can use an `a -> b` on it by -->
<!-- turning it into a `Maybe a -> Maybe b`. -->

<!-- That's neat and all...but, you might eventually realize that maybe you need a -->
<!-- little bit more some times. -->

<!-- Let's say that you have a matchmaking algorithm that calculates the -->
<!-- compatibility between two people. -->

<!-- ~~~haskell -->
<!-- compatibility :: Person -> Person -> Double -->
<!-- ~~~ -->

<!-- ~~~haskell -->
<!-- λ: compatibility John Sarah -->
<!-- 82.3 -->
<!-- ~~~ -->

<!-- That's fine and dandy if we are living in the world of normal functions and -->
<!-- normal types, but what if we were in the world of `Maybe`, the world of -->
<!-- uncertainty? -->

<!-- ~~~haskell -->
<!-- λ: personFromId 144 -->
<!-- Just John -->
<!-- λ: personFromId 14 -->
<!-- Just Sarah -->
<!-- λ: compatibility (personFromId 144) (personFromId 14) -->
<!-- << SCARY ERROR! >> -->
<!-- << compatibility takes two Persons, but you gave two Maybe Persons. >> -->
<!-- << have you no shame? >> -->
<!-- ~~~ -->

<!-- That didn't work, but what kind of answer would we have even expected? -->

<!-- Well, if we want to find the compatibility between two people that might not -->
<!-- even exist...the answer *should* be a compatibility that might not exist. -->

<!-- We want to move `compatibility :: Person -> Person -> Double`, and make it -->
<!-- work on two `Maybe Person`s; it'll work on two `Person`s inside the world and -->
<!-- create a `Double` inside the world. -->

<!-- We want some sort of "super `fmap`", that takes an `a -> b -> c` and turns it -->
<!-- into a `Maybe a -> Maybe b -> Maybe c`. -->

<!-- ~~~haskell -->
<!-- inMaybes :: (a -> b -> c) -> (Maybe a -> Maybe b -> Maybe c) -->
<!-- ~~~ -->

<!-- ~~~haskell -->
<!-- λ: (inMaybes compatibility) (personFromId 144) (personFromId 14) -->
<!-- Just 82.3 -->
<!-- λ: personFromId 59 -->
<!-- Nothing -->
<!-- λ: (inMaybes compatibility) (persomFromId 144) (personFromId 59) -->
<!-- Nothing -->
<!-- ~~~ -->

<!-- Note the last example --- you can't have a compatibility between a person that -->
<!-- exists and a person that doesn't exist! -->


<!-- ### Apply yourself -->

<!-- As you probably could have guessed, this but this pattern is actually -->
<!-- generalizable to many different worlds, like `Functor` was. -->

<!-- We call it `Applicative`.  And because `Maybe` is an `Applicative`, we have -->
<!-- access to `liftA2`: -->

<!-- ~~~haskell -->
<!-- liftA2 :: Applicative f => (a -> b -> c) -> (f a -> f b -> f c) -->
<!-- ~~~ -->

<!-- ~~~haskell -->
<!-- λ: (liftA2 compatibility) (personFromId 144) (personFromId 14) -->
<!-- Just 82.3 -->
<!-- ~~~ -->

<!-- What's the big deal about `Applicative`, anyway?  Do we need a separate, new -->
<!-- typeclass for just "`fmap` with two arguments"? -->

<!-- As it turns out, `Applicative` actually represents much more than just -->
<!-- `liftA2`.  `Applicative` *lets you combine values inside worlds*. -->

<!-- For example, in our previous example, we had `Maybe Person` and `Maybe -->
<!-- Person`, and we wanted to "combine" the *two* `Maybe`-things into *one* -->
<!-- `Maybe`-thing, a `Maybe Double` -->






--------

















--------------

















------------




Worlds of all sorts
-------------------

Let's look at a couple of other worlds we could exist in, and what it would
look like to move normal functions into them.

### Superpositions of possibilities

We looked at `Maybe`, which represents the return type of a function that
could possibly fail.  But let's look at the other end --- what about functions
that can possibly return multiple answers?

~~~haskell
evenUnder :: Int  -> [Int]
evenUnder n = filter even [1..(n-1)]

invSquare :: Double -> [Double]
invSquare x = [-sqrt x, sqrt x]

factorOf :: Int -> [Int]
factorOf n = filter ((== 0) . (n `mod`)) [1..n]
~~~

The idea is that when I call `evenUnder 8`, I get an answer that could validly
be 2, 4, or 6.  I enter a world of nondeterminism/superposition.  When I stay
in that world, I have to deal with the fact that my computation has multiple
possible answers.

~~~haskell
λ: evenUnder 8      -- what is an even number under 8?
[2,4,6]             -- (i'm giving you back a 2, 4, or 6 as possibilities)
~~~

It's easy to see how you can "exit" your world of superposition.  We already
made a funtion earliear that transported you from the world of superposition
to the world of uncertainty --- from there, we can exit completely.

~~~haskell
λ: headMaybe (factorOf 6)
Just 1
λ: certaintifyWithDefault 0 (headMaybe (factorOf 6))
1
~~~

(Interestingly enough, `headMaybe` is in the standard library in `Data.Maybe`
as `listToMaybe`)

But let's stay in this world.  Maybe in the end, we want to preserve the
nondeterminate properties of our computation.  For example...let's say we have
a function that looked up people by their favorite food, and that function
from person to age.  I want to write a function that, when given a food,
returns the age of every person who has it as their favorite food.

~~~haskell
isFavoriteFoodOf :: Food   -> [Person]
age              :: Person -> Int
favoriteFoodAges :: Food   -> [Int]
~~~

Clearly, we want to stay in nondeterminism/multiple possible answers the
entire time.

So, a type signature of `[a]` means "the result of my computation is many
possible answers."  What we need is a function that can take any ol' `a -> b`,
like `Person -> Int`, and make it work on `[Person]`.  That is, turn an `a ->
b` into a `[a] -> [b]`.

What would that even mean?

Well, if `invSquare 9` could possibly be -3 or 3, and we want to say "The
double of the inverse square"...that computation should yield -6 or 6.
Applying functions to a superposition values is like applying them to every
value.

`[]` is a `Functor`, so that means that it has such an `fmap :: (a -> b) ->
([a] -> [b])`.

~~~haskell
λ: let doubleInList = fmap (*2)
λ: :t doubleInList
[Int] -> [Int]
λ: let x = invSquare 9      -- x = [-3,3]
λ: doubleInList x
[-6,6]
λ: fmap addThree x
[0,6]
~~~

And so we can say

~~~haskell
favoriteFoodAges :: Food -> [Age]
favoriteFoodAges food = (fmap age) (isFavoriteFoodOf food)
~~~

Where we take our previous `age` function and bring it into "the world of
multiple `People`".

### The world of awaiting

Here's an interesting one.

In Haskell, we have a `Reader r` world.  You can think of `(Reader r) a` as a
little machine that "waits" for something of type `r`, then *uses* it to make
an `a`.

~~~haskell
λ: :t lengthReader
lengthReader :: (Reader [x]) Int
λ: runReader lengthReader [1,2,3]
3
λ: :t oddReader
oddReader :: (Reader Int) Bool
λ: runReader oddReader 6
False
λ: runReader oddReader 5
True
~~~

So if I have a `(Reader Int) Bool`, I have a `Bool` that "lives" in the
`Reader Int` world --- it is an ephemereal `Bool` awaiting an `Int` in order
to be realized and found.  It's a `Bool` *waiting to be produced* --- all it
needs is some `Int`.

Back to our database analogy, we can have a `Reader ID` world, a world where
all of its values are not there yet...they are in the future; they are
*waiting* for an `ID` to be able to realize themselves.

Let's say I have `personReader :: (Reader ID) Person` --- a future Person living
in the world of awaiting --- but I want `ageReader :: (Reader ID) Int`.  I
want to give someone an *age* that is just waiting for an `ID`.

Well, no fear!  Because `Reader ID` is a `Functor`, we can move the same old
`age :: Person -> Int` function that we have been using all along, into our
world of awaiting!

We can turn a `Person -> Int` into a `(Reader ID) Person -> (Reader ID) Int`.

~~~haskell
λ: runReader personReader 108
Jason
λ: age Jason
37
λ: let ageReader = (fmap age) personReader
λ: :t ageReader
ageReader :: (Reader ID) Person
λ: runReader ageReader 108
37
~~~

The *semantics* of `fmap` for `Reader Int` is that it applies that function to
the future value, once it has been obtained.  That is, once you get a `Person`
from the `ID`, it applies the function `age` to that `Person` before finally
popping it out.

Now we can move all of our functions into the world of awaiting!

### The world of state-modifying awaiters

Now, the world of awaiting might seem a little boring or uninteresting.  (And
you might have guessed that `(Reader r) a` is just a fancy wrapper around a
function `r -> a`)

But here's a slight twist to it.  Let's have a little machine `(State s) a`,
where it *awaits* an `s` to produce an `a` (like before), but it *modifies the
input in the process of producing* the `a`.[^modify]  It pops out not only the result,
but the modified `s`.

[^modify]: Of course, nothing is actually "modified" in-place in-memory ---
when we say `s` is modified, we mean that an altered version of the `s` is
returned.

~~~haskell
λ: :t popList
popList :: (State [a]) a
   -- pass the state `[8,1,5]` to the `popList` machine
λ: let (result, newstate) = runState popList [8,1,5]
λ: result
8
λ: newstate     -- list is changed in the process of making the 8
[1,5]
~~~

So we say this: `(State [Int]) Int` is a `Int` that lives in the world of
`State [Int]` --- it is awaiting a list of `Int`s before it can be fully
realized or known, and modifies that list in the process of its realization.

For `popList`, it is basically an `a` that is waiting to be realized if just
given an `[a]`.  The result is the first element, but in the process of
producing it, it leaves the list with one less element.

The `State s` world is a world of values waiting to be produced by an `s`, but
alter the `s` in the process.

Let's say we want have our `popList :: (State [Int]) Int` (for `Int`s).  How can
we stay "inside our state world" and give a `popIsEven :: (State [Int]) Bool`,
where it takes the first item off of the list and then tells if it is even or
not?

You got it --- `fmap`.

~~~haskell
λ: let (x,newstate) = runState popList [3,8,10] -- x        = 3
                                                -- newstate = [8,10]
λ: let popIsEven = fmap even popList
λ: :t popIsEven
popIsEven :: (State [Int]) Bool
λ: runState popIsEven newstate
(True, [10])
~~~

I think you get the picture at this point.  If I wanted to supply a `(State s)
b` (a machaine that popes out a `b`) but I only had a `(State s) a` (a machine
that pops out an `a`) and an `a -> b`, I could turn my `a -> b` into a `(State
s) a -> (State s) b` using `fmap`, because `State s` is a `Functor`!

I can apply normal functions and still remain in my
state-changing-result-realizing-machine world!




### Infamous IO

And then there is perhaps one of the more "infamous" worlds.  There is the
`IO` world.

But really, the `IO` world is a lot like the `Reader r` world!  Remember that
`Reader r Int` represents an `Int` living in a world that is waiting for an
`r` (the world of "awaiting").  `(Reader r) a` basically represents a
yet-to-be-realized `a` --- all you have to do is "run" it with that `r`.

In the same way, an `IO a` represents a yet-to-be-realized `a`.  It represents
*a computer routine that computes an `a` when run*.

An `IO a` is an object, like `(Reader r) a`, that, when compiled by the
appropriate compiler and then "run" by a computer, yields an `a`.  But only
when it is eventually run by the computer.

You can almost think of `IO a` as a literal chunk of machine code/C code that,
when run, will produce your `a`.

(Like for `(Reader r) a`, the `a` doesn't "exist" anywhere, *yet*.  But it
does after you run the `Reader`, in the future.  For `IO a`, the `a` doesn't
"exist" anywhere, yet.  The `a` is what that `IO` world promises to generate
when executed by a computer.)

This `IO` world --- world of things where you only describe *how* to produce
the thing (if you were a CPU) --- is unique among the ones we have looked at
before in that there is *no way to exit this world* in Haskell.

That is, where is no sort of meaningful function `IO a -> a`.  We had many
ways to "get out of" our previous worlds (`certaintify`, `runReader` and
`runState`, for example) and work with the naked values after they exit.

This kind of makes sense what you think about it.  If `IO a` is a little
chunk of machine code or an object containing instructions for some computer,
then the only thing that can really "get the `a`" is a computer --- and not a
Haskell program.  Because IO computations can involve things like disk reading
and getting input from the user and checking the weather...these are things
that you can't quite simulate.

Because you can never even meaningfully "exit" the `IO` world within a Haskell
program if you tried, a function like `fmap` is *extremely* handy.

Let's say our database of persons exists on a text file somewhere.  Because
processors and computers are very good at reading text files, `IO` looks like
a pretty nice world to live in.  So let's say we had a function

~~~haskell
lookupPerson :: ID -> IO Person
~~~

that looks up a person from a text file on disk somewhere, by their ID.  And
we want to write a function

~~~hasell
lookupAge :: ID -> IO Age
~~~

Remember, `lookupPerson i` is an object describing a computation that will
return a `Person` when a computer eventually runs it.

We can do some shifting, like we did for `Reader r`, and think of `IO Person`
as "a `Person` that lives in a world of awaiting being computed by a
computer."

We already have our normal `age :: Person -> Int` function, but this is
apparently useless!

~~~haskell
λ: age (lookupPerson 10)
<< SCARY ERROR! >>
-- > age only works on Person, but you gave it an IO Person, a Person that
-- > lives in IO.  You have to rethink your life, buddy.
~~~

But we can turn a `Person -> Int` into an `IO Person -> IO Int`.  Riiight?
Because `IO` is a `Functor`, and we have `fmap`!

~~~haskell
lookupAge :: ID -> IO Age
lookupAge i = (fmap age) (lookupPerson i)
~~~

Hooray `fmap`!  Thanks you you, we can bring normal functions into any world
we like, and we can stay in that world and use normal functions!

### Left Adjoint Fun

I'll leave a couple of notes here before moving on ---

First of all, even though we have been writing things like `(fmap f) x`, the
parentheses are actually unnecessary due to the way Haskell associates function
calls.  So `(fmap f) x` is the same as `fmap f x`, and we'll be writing it
that way from now on.

You probably could have guessed the same about the types `(Reader r) a` and
`(State s) a`, which are more traditionally written as `Reader r a` and `State
s a`.[^worldpar]

[^worldpar]: The parentheses are there to emphasize that `Reader r` is the
"world", and *not* `Reader`.  This is an important distinction.  `Reader Int
Bool` is a `Bool` living in the `Reader Int` world.

Finally, an infix operator alias for `fmap` exists: `(<$>)`.  That way, you
can write `fmap f x` as `f <$> x`, which is like "applying" `f` "inside" `x`.
This might be more useful or expressive in some cases.

Combining Worlds
----------------

After a while, you might notice that `fmap` and `Functor` has
some shortcomings.

Let's return to the world of `Maybe`, and our database of people.  Let's say
that you have a matchmaking algorithm that calculates the compatibility
between two people.

~~~haskell
compatibility :: Person -> Person -> Double
~~~

~~~haskell
λ: compatibility John Sarah
82.3
~~~

That's fine and dandy if we are living in the world of normal functions and
normal types, but what if we were in the world of `Maybe`, the world of
uncertainty?

~~~haskell
λ: personFromId 144
Just John
λ: personFromId 14
Just Sarah
λ: compatibility (personFromId 144) (personFromId 14)
<< SCARY ERROR! >>
-- > compatibility takes two Persons, but you gave two Maybe Persons.
-- > do you have no shame?
~~~

That didn't work, but what kind of answer would we have even expected?

Well, if we want to find the compatibility between two people that might not
even exist...the answer *should* be a compatibility that might not exist.

That is:

~~~haskell
compatiblityInMaybes :: Maybe Person -> Maybe Person -> Maybe Double
~~~

~~~haskell
λ: compatibilityInMaybes (personFromId 144) (personFromId 14)
Just 82.3
λ: personFromId 59
Nothing
λ: compatibilityInMaybes (persomFromId 144) (personFromId 59)
Nothing
~~~

For the last answer, the compatibility between someone that does exist and
someone that doesn't exist ... well, doesn't exist!

### Apply Yourself

You might be guessing that, like `Functor` and `fmap`, this is a common design
pattern as well, that might be expanded to different worlds.

And you're right.  It's called `Applicative`.  And instead of `fmap`, we have
a new grab bag of functions that are aimed at *combining values inside
worlds*.

For `Functor`, we have functions aimed at *applying functions inside worlds*.
`Applicative` comes along and lets us *combine values inside worlds*.

For that, we have a handy function called `liftA2`.

~~~haskell
liftA2 :: Applicative f => (a -> b -> c) -> (f a -> f b -> f c)
~~~

And because `Maybe` is an `Applicative`, we can jump right away into turning
`compatibility :: Person -> Person -> Double` into a `Maybe Person -> Maybe
Person -> Maybe Double`

~~~haskell
λ: (liftA2 compatibility) (personFromId 144) (personFromId 14)
Just 82.3
--  remember, the parentheses are optional
λ: liftA2 compatibility (personFromId 144) (persomFromId 59)
Nothing
~~~

Using `Applicative`, we were able to combine two `Maybe a` values into one
`Maybe c`.  We were able to "combine" two values inside the same world.

`Applicative` also offers `liftA3`, and tools to combine arbitrary numbers of
worlds.

<aside>
    ###### Aside

`Applicative` actually is a little "deeper" than just `liftA2`.  If you
peek into the definition of `Applicative`, you'll see that it doesn't even
mention `liftA2`worlds.:

~~~haskell
class Functor f => Applicative f where
    pure  :: a -> f a
    (<*>) :: f (a -> b) -> f a -> f b
~~~

You probably could guess the semantics/meaning of `pure` and `(<*>)` when we
think about worlds:

*   `pure` lets us "enter" a world, for free.

    The only meaningful implementation in `Maybe` is of course to just wrap
    the value in a `Just` --- a `Maybe` value that is *there*, obviously.

*   `(<*>)` applies the function inside the world on the left hand side to the
    value inside the world on the right hand side, all staying in the world
    the entire time.

Using this, we can write things like `liftA2 f x y` and `liftA3 f x y z` as

~~~haskell
liftA2 :: (a -> b -> c) -> f a -> f b -> f c
liftA2 f x y = f <$> x <*> y

liftA3 :: (a -> b -> c -> d) -> f a -> f b -> f c -> f d
liftA3 f x y z = f <$> x <*> y <*> z
~~~


How does this work?  It's not magic.  If we add explicit parentheses, can see
that the above definition of `liftA2` is just

~~~haskell
(f <$> x) <*> y
~~~

And if `f :: a -> b -> c`, and `x :: Maybe a`, then `fmap f x` is `Maybe (b ->
c)` (because of currying).

So if `(f <$> x)` is `Maybe (b -> c)` --- that is, a function that might or
might not exist --- we can use `<*>` to apply that function to our `Maybe b`
to get a `Maybe c`.

If you don't understand this, don't worry; you can sort of just read `f <$> x
<*> y` as "apply `f` 'inside' `x` and `y`", and `f <$> x <*> y <*> z` as
"apply `f` 'inside' `x`, `y`, and `z`".

</aside>


#### Other worlds are Applicatives too

Other worlds are `Applicative`s too.  In fact, I sort of specifically picked
worlds that were both `Functor` and `Applicative`; how clever of me!

##### State Applicative

Combining two `State s` machines has interesting semantics.

What would it even mean to combine two machines that take in and modify a
state, and create a new machine that takes in and modifies a state?

Let's think about something like

~~~haskell
pop2 :: State [a] (a,a)
pop2 = (liftA2 (,)) popList popList
~~~

where `(,)` is the tupling function `a -> b -> (a, b)`.

The type of `pop2` should tell you that it is some sort of state machine that
takes in an `[a]` as a state, and produces an `(a,a)` and pops out a modified
`[a]` in the process.

The *semantics* of "combining" two `State s` machines is that when you
"combine" two machines, you create a new machine that feeds the input state
into the first machine, feeds the modified state of the first machine into the
second machine, and then pops out finally the modified state of the second
machine.

<!-- TODO: Add a diagram here -->

So `pop2` should basically take something like `[1,2,3,4]`, give it to the first
`popList`, which would output `[2,3,4]`, which would then be fed into the
second `popList`, which would output `[3,4]`, which would be the final
modified state.

~~~haskell
λ: let (result, newstate) = runState pop2 [1,2,3,4]
λ: newstate
[3,4]
~~~

And what would `result` be?

Well, `popList` "contains" a to-be-realized `Int` (awaiting an `[Int]` to
realize itself).  So to apply `(,)` "inside" the `State [Int]` world, we would
just take those two to-be-realized `Int`'s...and tuple them.  We create a
to-be-realized `(Int, Int)`!

And that's exactly what `State [Int] (Int, Int)` means!

So, `(liftA2 (,)) popList popList` snags up those two to-be-realized `Int`s,
and couples them up into a to-be-realized tuple, `(Int, Int)`.

The big picture --- we can stay in our "to-be-realized" world, and *still* use
our normal functions like `(,)`.  Not only that, we can combine the two
results "living" in the "to-be-realized" world, into one "to-be-realized"
world.

So back to what `result` must be --- the first `popList` pops an item off of
`[1,2,3,4]` and "realizes" a 1.  The second `popList` pops an item off of
`[2,3,4]` and "realizes" a 2.  So `pop2` on `[1,2,3,4]` should snag up those
two "realized" numbers 1 and 2 and realize a `(1, 2)`.

~~~haskell
λ: let (result, newstate) = runState pop2 [1,2,3,4]
λ: result
(1,2)
~~~

Neat.


#### The IO Applicative

`IO` is, too, an `Applicative`.  But what does that mean?

Well, if we have two "instructions on how to compute" something, we have two
values living in a "to-be-computed-in-the-future-by-a-computer" world.

Let's see what that would mean?

Let's take the classic `IO String` --- a `String` living in that world ---
`getLine :: IO String`.  `getLine` is describes, for the computer, the act of
reading a line from stdin, and the string that it promises to deliver is that
line.

So what would something like

~~~haskell
getTwoLines :: IO String
getTwoLines = (liftA2 (++)) getLine getLine
~~~

do?

`getTwoLines` is an IO computation --- a object describing a
computation --- that does `getLine` *twice* to get those two `String`s that
`getLine` promises, and then applies `(++)` to those realized `Strings` to get
a realized `String` that is the concatenation of both.

So `getTwoLines` is an IO computation that promises a `String`.  Where does it
come from?  Well, the two `getLine`s both promise `String`s.  `getTwoLines`
runs the two one after the other, and *promises* to deliver the concatenation
(the `(++)`) of the two strings promised by the `getLine`s.

### Applicati-cations

What did we just see?

*   A way to move any function working on normal values to work on values
    inside our worlds.

    In types, a way to move `a -> b` into `f a -> f b`.

*   A way to "combine" two values inside worlds into just one.

    And in the process, a way to move `a -> b -> c` into `f a -> f b -> f c`.

It looks like with these two tools, working with values inside worlds seems to
really be no biggie at all.  We can use normal functions just fine, and take
advantage of maximum code re-use.  Imagine having to write two separate
`age` functions for both `Person` and `Maybe Person`!

One very important thing to note here is that *what it actually means* to be
moved "into world" depends on the actual world.  And this is the power of the
abstraction --- every world can offer its own way of lifting functions.  All
`Functor` and `Applicative` say is: if there is a meaningful way to move this
into this world, here it is.

Note that I didn't go over what it would look like to combine `[]` and `Reader
r`.  Feel free to try to interpret it yourself!

Chaining worlds
---------------

There's just one tool that we need to yet add to our arsenal to make this
complete.

I claim that I can stay inside `Maybe` forever.  But what if I had `Just 8 ::
Maybe Int` and I wanted to apply `halveMaybe :: Int -> Maybe Int` to it?

This sounds like something that I should be able to do.  After all, both `Just
7` and `halveMaybe` deal with uncertainty.  `Just 8` is a value that might or
might not be there, and `halveMaybe` is a function that produces a number that
might or not not be there.

We stay inside the world of uncertainty the entire time.  No biggie!

If I wanted to somehow be able to apply `halveMaybe` to `Just 8`, I would
expect something like `Just 4`.

If I wanted to apply `halveMaybe` to `Nothing`, I would expect...well,
`Nothing`.  If I apply it to `Just 7`, I'd expect `Nothing`.  Makes sense,
right?

So how do we get `Int -> Maybe Int` to work on `Maybe Int`?

What we are really looking for is a way to turn `a -> Maybe b` into `Maybe a
-> Maybe b`

Hm.  This is harder than it looks at first.  We can't use `fmap`:

~~~haskell
λ: fmap halveMaybe (Just 8)
Just (Just 4)   -- :: Maybe (Maybe Int)
λ: fmap halveMaybe (Just 7)
Just Nothing    -- :: Maybe (Maybe Int)
~~~

`fmap` turns an `Int -> Maybe Int` into a `Maybe Int -> Maybe (Maybe Int)`.
It "lifts" both sides.

Let's imagine we had a function `preLift :: (a -> Maybe b) -> (Maybe a ->
Maybe b)`

Compare:

~~~haskell
fmap    :: (a ->       b) -> (Maybe a -> Maybe b)
preLift :: (a -> Maybe b) -> (Maybe a -> Maybe b)
~~~

And now we can finally properly apply `halveMaybe` to `Just 8`:

~~~haskell
λ: (preLift halveMaybe) (Just 8)
Just 4
λ: (preLift halveMaybe) Nothing
Nothing
λ: (preLift halveMaybe) (Just 7)
Nothing
~~~

We can write `preLift` ourselves:

~~~haskell
preLift :: (a -> Maybe b) -> (Maybe a -> Maybe b)
preLift f = go
  where
    go Nothing  = Nothing
    go (Just x) = f x
~~~

And just like that...we have found our final, integral tool.

### Monads

Like with `Functor` and `Applicative`, `Monad` generalizes a special type of
application to many worlds and offers a common interface.

And this functionality (with some other things) --- the ability to turn an `a
-> Maybe b` into a `Maybe a -> Maybe b` --- gives you the `Monad` typeclass.
Not so scary, is it?

There unfortunately actually isn't a named function that does what `preLift`
does.  However, there is an operator --- `(=<<)`:

~~~haskell
λ: halveMaybe =<< Just 8
Just 4
λ: halveMaybe =<< Nothing
Nothing
λ: halveMaybe =<< Just 7
Nothing
~~~

Note the similarities between `(=<<)` and the infix `fmap`, `(<$>)`:

~~~haskell
λ: addThree <$> Just 8
Just 11
λ: halveMaybe =<< Just 8
Just 4
λ: :t (<$>)
(<$>) :: Functor f => (a ->   b) -> f a -> f b
λ: :t (=<<)
(=<<) :: Monad f   => (a -> f b) -> f a -> f b
~~~

`(<$>)` lifts an `a -> b` to `f a -> f b`, and `(=<<)` lifts an `a -> f b` to
`f a -> f b`.

The *target* (`f a -> f b`) is the *same* for both.  But the inputs are
slightly different.

Let's see `(=<<)` in action for our multitude of worlds!

<aside>
    ###### Aside

`Monad` is only slightly more than just `(=<<)`:

~~~haskell
class Monad m where
    return :: a -> m a
    (>>=)  :: m a -> (a -> m b) -> m b
~~~

`return` is just `pure` --- it "injects" a value straight up into your world.
And `(>>=)` is just `(=<<)` reversed.

`Monad`s are encouraged to follow a couple of laws that we won't go into too
much detail here.
</aside>

### More Monads!

Because, remember, every world their its own unique semantics that make them all
uniquely useful, let's see what this sort of "lifting" would look like in
different worlds.

#### State Monad

We can look at what `(=<<)` must mean for the world of `State s`.

If I have something like `f :: a -> State s b`, that must mean that `f` is a
function from a value to a state-modifying machine.

Let's say I already had an `x :: State s a`.  A state modifying machine that
promises an `a`, but requires and modifies an input `s`.  And I wanted to
apply `f` "to it".

Well...`f` would just be applied to that `a` promised by `x`!

And so, `f =<< x` would be of type `State s b`, where the `b` is the
yet-to-be-realized value that is the result of applying `f` to the
yet-to-be-realized result of `x`.

Let's look at an example.

~~~haskell
pushList :: a -> State [a] ()
popList  :: State [a] a
~~~

`popList` contains an `a` that is yet to be computed, and is waiting for an
`[a]` that it will change in that process (by removing an element).

`pushList` takes an `a` and returns a `()` --- more more specifically, a `()`
that is yet to be computed, and is waiting for an incoming list `[a]` that it
will change in that process (by appending the element).

~~~haskell
λ: let push5 = pushList 5   -- State [Int] ()
λ: let (result,newstate) = runState push5 [1,2,3]
λ: newstate
[5,1,2,3]
~~~

So if we looked at `(pushList =<<)` here, we see a `State [Int] Int -> State
[Int] ()`.  That is, we turned `pushList` into a function that takes a `State
[Int] Int` instead of an `Int`.

It takes to-be-realized `Int`.  Well, it'll just use that to-be-realized `Int`
and feed it into `pushList`!

So `(pushList =<<)` takes a to-be-realized `a` and turns it into a
to-be-realized `()`.  Sound like `fmap` to you?

What would happen if we did `pushList =<< popList` ?

~~~haskell
λ: let popPush = pushList =<< popList
λ: let (result,newstate) = runState popPush [1,2,3,4]
λ: result
()
~~~

Okay, well, the result is what we would expect.  What about the newly modified
`s`?

Well, `(=<<)` for `State s` is implemented so that `pushList =<< popList`
creates a new machine, who takes in a state, runs it to to `popList`, takes
the resulting state and feeds it into the state input of the `pushList i`
machine.

In our case, `popList` takes an item off the list and returns the value.
`pushList` takes a value and adds it onto the list.

For `pushList =<< popList`, if we ran something like `[1,2,3,4]`:

1.  `popList` takes in the `[1,2,3,4]` state and proudly makes a 1 and pops
    out a state of `[2,3,4]`.
2.  `pushList` is called with 1 to get `pushList 1 :: State [Int] ()`.  The
    state `[2,3,4]` is fed into `pushList 1` to get `[1,2,3,4]`.

~~~haskell
λ: let (result,newstate) = runState pushPop [1,2,3,4]
λ: newstate
[1,2,3,4]
~~~



<!-- The semantics work in that the new `State s b` is a new state-modifying -->
<!-- machine.  It takes an input of type `s`, feeds it into the first machine, -->







----











------

[iopure]: http://blog.jle.im/entry/the-compromiseless-reconciliation-of-i-o-and-purity
[state]: http://blog.jle.im/entry/streaming-huffman-compression-in-haskell-part-1-trees#the-state-monad

