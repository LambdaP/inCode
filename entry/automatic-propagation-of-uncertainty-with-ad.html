<!DOCTYPE HTML>
<html><head><title>Automatic Propagation of Uncertainty with AD · in Code</title><meta name="description" content="Weblog of Justin Le, covering his various adventures in programming and explorations in the vast worlds of computation physics, and knowledge."><meta http-equiv="Content-Type" content="text/html;charset=utf-8"><meta name="viewport" content="width=device-width,initial-scale=1.0"><meta property="og:site_name" content="in Code"><meta property="og:description" content="Some of my favorite Haskell tricks involve working with exotic numeric types with custom overloaded numeric functions and literals that let us work with data in surprisingly elegant and expressive ways. Here is one example — from my work in experimental physics and statistics, we often deal with experimental/sampled values with inherent uncertainty. If you ever measure something to be 12.4\,\mathrm{cm}, that doesn’t mean it’s 12.400000\,\mathrm{cm}, it means that it’s somewhere between 12.3\,\mathrm{cm} and 12.5\,\mathrm{cm}…and we don’t know exactly. We can write it as 12.4 \pm 0.1\,\mathrm{cm}. The interesting thing happens when we try to add, multiply, divide numbers with uncertainty. What happens when you add 12 \pm 3 and 19 \pm 6? The initial guess might be 27 \pm 9, because one is \pm 3 and the other is \pm 6. But! If you actually do experiments like this several times, you’ll see that this isn’t the case. If you tried this out experimentally and simulate several hundred trials, you’ll see that the answer is actually something like 31 \pm 7. Let’s write ourselves a Haskell data type that lets us work with numbers with inherent uncertainty:"><meta property="og:type" content="article"><meta property="og:title" content="Automatic Propagation of Uncertainty with AD"><meta property="og:image" content="https://blog.jle.im/img/site_logo.jpg"><meta property="og:locale" content="en_US"><meta property="og:url" content="https://blog.jle.im/entry/automatic-propagation-of-uncertainty-with-ad.html"><meta name="twitter:card" content="summary"><meta name="twitter:creator:id" content="mstk"><link rel="author" href="https://plus.google.com/107705320197444500140"><link rel="alternate" type="application/rss+xml" title="in Code (RSS Feed)" href="http://feeds.feedburner.com/incodeblog"><link rel="canonical" href="https://blog.jle.im/entry/automatic-propagation-of-uncertainty-with-ad.html"><link href="https://blog.jle.im/favicon.ico" rel="shortcut icon"><link href="https://blog.jle.im/css/toast.css" rel="stylesheet" type="text/css"><link href="https://blog.jle.im/css/font.css" rel="stylesheet" type="text/css"><link href="https://blog.jle.im/css/main.css" rel="stylesheet" type="text/css"><link href="https://blog.jle.im/css/page/entry.css" rel="stylesheet" type="text/css"><link href="https://blog.jle.im/css/pygments.css" rel="stylesheet" type="text/css"><script type="text/javascript">var page_data = {};
var disqus_shortname='incode';
</script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-443711-8', 'jle.im');
ga('send', 'pageview');
</script><script type="text/javascript" src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5234d67a6b68dcd4"></script><script type="text/javascript" src="https://blog.jle.im/js/common.js"></script><script type="text/javascript" src="https://blog.jle.im/js/page/entry_toc.js"></script><script type="text/javascript" src="https://blog.jle.im/js/disqus_count.js"></script><script type="text/javascript" src="https://blog.jle.im/js/social.js"></script><script type="text/javascript" src="https://blog.jle.im/js/jquery/jquery.toc.js"></script><script type="text/javascript" src="https://blog.jle.im/purescript/entry.js"></script></head><body><div id="fb-root"><script>(function(d, s, id) {
 var js, fjs = d.getElementsByTagName(s)[0];
 if (d.getElementById(id)) return;
 js = d.createElement(s); js.id = id;
 js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=641852699171929";
 fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));
</script></div><div id="header-container"><div id="navbar-container" class="tile"><nav id="navbar-content"><div class="nav-info"><h1 class="site-title"><a href="https://blog.jle.im/" class="nav-title">in Code</a></h1><span class="nav-author">Justin Le</span></div><ul class="nav-links"><li><a href="https://blog.jle.im/">home</a></li><li><a href="https://blog.jle.im/entries.html">archives</a></li><div class="clear"></div></ul></nav></div><div id="header-content"></div></div><div id="body-container" class="container"><div id="main-container" class="grid"><div class="entry-section unit span-grid" role="main"><article class="tile article"><header><div class="unposted-banner">Unposted entry</div><h1 id="title">Automatic Propagation of Uncertainty with AD</h1><p class="entry-info">by <a class="author" href="https://blog.jle.im/">Justin Le</a></p><p><span class="source-info"><a class="source-link" href="https://github.com/mstksg/inCode/tree/master/copy/entries/uncertainty.md">Source</a><span class="info-separator"> &diams; </span><a class="source-link" href="https://blog.jle.im/entry/automatic-propagation-of-uncertainty-with-ad.md">Markdown</a><span class="info-separator"> &diams; </span><a class="source-link" href="https://blog.jle.im/entry/automatic-propagation-of-uncertainty-with-ad.tex">LaTeX</a><span class="info-separator"> &diams; </span></span>Posted in <a href="https://blog.jle.im/entries/category/@haskell.html" class="tag-a-category" title="Functional, pure, non-strict, statically and strongly typed, natively
compiled…really just the king of great languages.">Haskell</a>, <a href="https://blog.jle.im/entries/category/@tutorials.html" class="tag-a-category" title="Technical tutorials/walkthroughs on specific programming processes and
problems that I’ve struggled through in the past.">Tutorials</a><span class="info-separator"> &diams; </span><a class="comment-link" href="#disqus_thread">Comments</a></p></header><hr><aside class="contents-container"><h5 id="contents-header">Contents</h5><div id="toc"></div></aside><div class="main-content copy-content"><p>Some of my favorite Haskell “tricks” involve working with exotic numeric types with custom “overloaded” numeric functions and literals that let us work with data in surprisingly elegant and expressive ways.</p>
<p>Here is one example — from my work in experimental physics and statistics, we often deal with experimental/sampled values with inherent uncertainty. If you ever measure something to be <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?12.4%5C%2C%5Cmathrm%7Bcm%7D" alt="12.4\,\mathrm{cm}" title="12.4\,\mathrm{cm}" />, that doesn’t mean it’s <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?12.400000%5C%2C%5Cmathrm%7Bcm%7D" alt="12.400000\,\mathrm{cm}" title="12.400000\,\mathrm{cm}" />, it means that it’s somewhere between <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?12.3%5C%2C%5Cmathrm%7Bcm%7D" alt="12.3\,\mathrm{cm}" title="12.3\,\mathrm{cm}" /> and <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?12.5%5C%2C%5Cmathrm%7Bcm%7D" alt="12.5\,\mathrm{cm}" title="12.5\,\mathrm{cm}" />…and we don’t know exactly. We can write it as <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?12.4%20%5Cpm%200.1%5C%2C%5Cmathrm%7Bcm%7D" alt="12.4 \pm 0.1\,\mathrm{cm}" title="12.4 \pm 0.1\,\mathrm{cm}" />.</p>
<p>The interesting thing happens when we try to add, multiply, divide numbers with uncertainty. What happens when you “add” <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?12%20%5Cpm%203" alt="12 \pm 3" title="12 \pm 3" /> and <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?19%20%5Cpm%206" alt="19 \pm 6" title="19 \pm 6" />?</p>
<p>The initial guess might be <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?27%20%5Cpm%209" alt="27 \pm 9" title="27 \pm 9" />, because one is <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?%5Cpm%203" alt="\pm 3" title="\pm 3" /> and the other is <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?%5Cpm%206" alt="\pm 6" title="\pm 6" />.</p>
<p>But! If you actually do experiments like this several times, you’ll see that this isn’t the case. If you tried this out experimentally and simulate several hundred trials, you’ll see that the answer is actually something like <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?31%20%5Cpm%207" alt="31 \pm 7" title="31 \pm 7" />.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<p>Let’s write ourselves a Haskell data type that lets us work with “numbers with inherent uncertainty”:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">ghci<span class="fu">&gt;</span> <span class="kw">let</span> x <span class="fu">=</span> <span class="fl">14.6</span> <span class="fu">+/-</span> <span class="fl">0.8</span>
ghci<span class="fu">&gt;</span> <span class="kw">let</span> y <span class="fu">=</span> <span class="dv">31</span>   <span class="fu">+/-</span> <span class="dv">2</span>
ghci<span class="fu">&gt;</span> x <span class="fu">+</span> y
<span class="dv">46</span> <span class="fu">+/-</span> <span class="dv">2</span>
ghci<span class="fu">&gt;</span> x <span class="fu">*</span> y
<span class="dv">450</span> <span class="fu">+/-</span> <span class="dv">40</span>
ghci<span class="fu">&gt;</span> sqrt (x <span class="fu">+</span> y)
<span class="fl">6.8</span> <span class="fu">+/-</span> <span class="fl">0.2</span>
ghci<span class="fu">&gt;</span> logBase y x
<span class="fl">0.78</span> <span class="fu">+/-</span> <span class="fl">0.02</span>
ghci<span class="fu">&gt;</span> log (x<span class="fu">**</span>y)
<span class="fl">85.9</span> <span class="fu">+/-</span> <span class="fl">0.3</span></code></pre></div>
<p>Along the way, we’ll also learn how to harness the power of awesome <a href="http://hackage.haskell.org/package/ad">ad</a> library, a library used in implementing back-propagation and other optimization algorithms, to analyze numerical functions in a mathematical way and break down their derivatives and gradients.</p>
<h2 id="certain-uncertainty">Certain Uncertainty</h2>
<p>First of all, let’s think about why adding two “uncertain” values doesn’t involve simply adding the uncertainties linearly.</p>
<p>If I have a value <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?16%20%5Cpm%203" alt="16 \pm 3" title="16 \pm 3" /> (maybe I have a ruler whose ticks are 2 units apart, or an instrument that produces measurements with 4 units of noise), it either means that it’s a little below 16 or a little above 16. If I have an independently sampled value <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?25%20%5Cpm%204" alt="25 \pm 4" title="25 \pm 4" />, it means that it’s a little below 25 or a little above 25.</p>
<p>What happens if I want to think about their sum? Well, it’s going to be somewhere around 41. But, the uncertainty won’t be <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?%5Cpm%207" alt="\pm 7" title="\pm 7" />. In order for that to be possible, the errors in the two values have to <em>always be aligned</em>. Only when every “little bit above” 16 error lines up perfectly with a “little bit above” 25 error, and when every single “little bit below” 16 error lines up perfectly with a “little bit above” 25 error, would you really get something that is <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?%5Cpm%207" alt="\pm 7" title="\pm 7" />.</p>
<p>But our two values were sampled independently, and so they are uncorrelated. You shouldn’t expect that if your <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?16%20%5Cpm%203" alt="16 \pm 3" title="16 \pm 3" /> value is ever “a little bit above”, then the <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?25%20%5Cpm%204" alt="25 \pm 4" title="25 \pm 4" /> value is also “a little bit above”, as well. They’re uncorrelated and independent, so their errors won’t actually always align. Instead, you’ll get a variance that’s <em>less than</em> <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?%5Cpm%207" alt="\pm 7" title="\pm 7" />, because a lot of times the deviations will “cancel out”. We can mathematically derive that the variance will be exactly (in a platonic way) <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?%5Cpm%205" alt="\pm 5" title="\pm 5" />.</p>
<p>In general, we find that, for <em>independent</em> <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?X" alt="X" title="X" /> and <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?Y" alt="Y" title="Y" />:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?%0A%5Coperatorname%7BVar%7D%5BaX%20%2B%20bY%20%2B%20c%5D%20%3D%20a%5E2%20%5Csigma_X%5E2%20%2B%20b%5E2%20%5Csigma_Y%5E2%0A" alt="
\operatorname{Var}[aX + bY + c] = a^2 \sigma_X^2 + b^2 \sigma_Y^2
" title="
\operatorname{Var}[aX + bY + c] = a^2 \sigma_X^2 + b^2 \sigma_Y^2
" /><br /></p>
<p>Where <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?%5Csigma_X%5E2" alt="\sigma_X^2" title="\sigma_X^2" /> is the variance in <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?X" alt="X" title="X" />. We consider <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?%5Csigma_X" alt="\sigma_X" title="\sigma_X" /> to be the standard deviation of <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?X" alt="X" title="X" />, or the “plus or minus” part of our numbers.</p>
<p>In the simple case of addition, we have <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?%5Coperatorname%7BVar%7D%5BX%20%2B%20Y%5D%20%3D%20%5Csigma_X%5E2%20%2B%20%5Csigma_Y%5E2" alt="\operatorname{Var}[X + Y] = \sigma_X^2 + \sigma_Y^2" title="\operatorname{Var}[X + Y] = \sigma_X^2 + \sigma_Y^2" />, so our new uncertainty is <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?%5Csqrt%7B%5Csigma_X%5E2%20%2B%20%5Csigma_Y%5E2%7D" alt="\sqrt{\sigma_X^2 + \sigma_Y^2}" title="\sqrt{\sigma_X^2 + \sigma_Y^2}" />.</p>
<p>However, not all functions that combine <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?X" alt="X" title="X" /> and <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?Y" alt="Y" title="Y" /> can be expressed as simple linear combinations <img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?aX%20%2B%20bY%20%2B%20c" alt="aX + bY + c" title="aX + bY + c" />. But! If you dig back to your days of high school calculus, you might remember a method for expressing any arbitrary function as a linear approximation – the <a href="https://en.wikipedia.org/wiki/Taylor_series">Taylor Expansion</a>!</p>
<p>In general, we can attempt to approximate any well-behaving function as its tangent hyperplane:</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?%0Af%28x_0%20%2B%20x%2C%20y_0%20%2B%20y%29%20%5Capprox%0A%5Cfrac%7B%5Cpartial%20f%7D%7B%5Cpartial%20x%7D%7C_%7Bx_0%2C%20y_0%7D%20x%20%2B%20%0A%5Cfrac%7B%5Cpartial%20f%7D%7B%5Cpartial%20y%7D%7C_%7Bx_0%2C%20y_0%7D%20y%20%2B%20%0Af%28x_0%2C%20y_0%29%0A" alt="
f(x_0 + x, y_0 + y) \approx
\frac{\partial f}{\partial x}|_{x_0, y_0} x + 
\frac{\partial f}{\partial y}|_{x_0, y_0} y + 
f(x_0, y_0)
" title="
f(x_0 + x, y_0 + y) \approx
\frac{\partial f}{\partial x}|_{x_0, y_0} x + 
\frac{\partial f}{\partial y}|_{x_0, y_0} y + 
f(x_0, y_0)
" /><br /></p>
<p>Look familiar? This is exactly the form that we used earlier to calculate “combined” variance!</p>
<p><br /><img style="vertical-align:middle" src="https://latex.codecogs.com/gif.latex?%0A%5Coperatorname%7BVar%7D%5Bf%28X%2CY%29%5D%20%5Capprox%20%0A%5Cfrac%7B%5Cpartial%20f%7D%7B%5Cpartial%20x%7D%7C_%7B%5Cmu_X%2C%20%5Cmu_Y%7D%5E2%20%5Csigma_X%5E2%20%2B%0A%5Cfrac%7B%5Cpartial%20f%7D%7B%5Cpartial%20x%7D%7C_%7B%5Cmu_X%2C%20%5Cmu_Y%7D%5E2%20%5Csigma_Y%5E2%0A" alt="
\operatorname{Var}[f(X,Y)] \approx 
\frac{\partial f}{\partial x}|_{\mu_X, \mu_Y}^2 \sigma_X^2 +
\frac{\partial f}{\partial x}|_{\mu_X, \mu_Y}^2 \sigma_Y^2
" title="
\operatorname{Var}[f(X,Y)] \approx 
\frac{\partial f}{\partial x}|_{\mu_X, \mu_Y}^2 \sigma_X^2 +
\frac{\partial f}{\partial x}|_{\mu_X, \mu_Y}^2 \sigma_Y^2
" /><br /></p>
<p>neat, huh?</p>
<!-- Some people like to talk about probability and statistics as "inexact maths" or -->
<!-- "non-deterministic math", but the exact opposite is true.  Probability and -->
<!-- statistics is the *exact*, rigorous, and *deterministic* math of -->
<!-- non-deterministic domains. -->
<!-- But first, let's think about why adding -->
<!-- Quantum mechanics, after all, is one of the most -->
<!-- exact and deterministic triumphs of mathematical physics -- despite what you -->
<!-- might hear in physics popularisations.[^qm] -->
<!-- [^qm]: Quantum mechanics, the discipline, makes very precise, exact, and -->
<!-- testable predictions about probability distributions and non-deterministic -->
<!-- processes, and the predictions of quantum mechanics are some of the most -->
<!-- precisely tested and verified predictions in the history of physics. -->
<!-- ~~~haskell -->
<!-- 46 +/- 2 -->
<!-- 450 +/- 41 -->
<!-- 6.8 +/- 0.2 -->
<!-- 0.78 +/- 0.02 -->
<!-- 83 +/- 6 -->
<!-- ~~~ -->
<!-- That's because more often than not, the errors in both -->
<!-- values will "cancel each other out" -- it's relatively unlikely that they'll -->
<!-- both error in the same direction, and so when you add two uncertain values -->
<!-- together, their uncertainties tend to cancel each other out. -->
<!-- One of my favorite Haskell magic tricks is "automatic differentiation", "ad", -->
<!-- which is a surprising application of Haskell's overloaded numeric -->
<!-- typeclasses/literals, simple algebraic data type manipulation, and universal -->
<!-- quantification.  The magic happens when you think you're calculating normal -->
<!-- numeric functions with `+` and `*` and `sin`, etc.,...but you're actually -->
<!-- calculating their derivatives instead. -->
<!-- ~~~haskell -->
<!-- ghci> diff (\x -> x^2) 10 -->
<!-- 20 -->
<!-- ghci> diff (\x -> sin x) 0 -->
<!-- 1.0 -->
<!-- ghci> diff (\x -> sin (x^3)) -->
<!-- 0.47901729549851046 -->
<!-- ~~~ -->
<!-- We define a new data type with a funky `Num` instance, so instead of defining -->
<!-- $x^3$ as actual exponentiation, we define it to return $3x^2 \dot{x}$ instead, -->
<!-- etc. It's a rather cute technique and something that's accessible to any -->
<!-- Haskell beginner. -->
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>If you don’t believe me, stop reading this article now and try it yourself! You can simulate noisy data by using uniform noise distributions, Gaussian distributions, or however manner you like. Verify by checking the <a href="https://en.wikipedia.org/wiki/Variance">variance</a> of the sum.<a href="#fnref1">↩</a></p></li>
</ol>
</section></div><footer><ul class="entry-series"></ul><ul class="tag-list"><li><a href="https://blog.jle.im/entries/tagged/haskell.html" class="tag-a-tag">#haskell</a></li><li><a href="https://blog.jle.im/entries/tagged/numerical-methods.html" class="tag-a-tag">#numerical methods</a></li><li><a href="https://blog.jle.im/entries/category/@haskell.html" class="tag-a-category">@HASKELL</a></li><li><a href="https://blog.jle.im/entries/category/@tutorials.html" class="tag-a-category">@TUTORIALS</a></li></ul><aside class="social-buttons"><div class="addthis_toolbox addthis_default_style addthis-buttons"><a class="addthis_button_facebook_like" fb:like:layout="button_count"></a><a class="addthis_button_tweet"></a><a class="addthis_button_google_plusone" g:plusone:size="medium"></a><a class="addthis_counter addthis_pill_style"></a></div><div class="custom-social-buttons"><div class="custom-social-button"><a href="https://www.reddit.com/submit" onclick="window.location = &#39;https://www.reddit.com/submit?url=&#39;+ encodeURIComponent(window.location); return false"><img src="https://www.reddit.com/static/spreddit7.gif" alt="submit to reddit"></a></div></div></aside><nav class="next-prev-links"><ul><li class="next-entry-link">(Next) <a href="https://blog.jle.im/entry/introducing-in-code.html">Introducing “in Code”!</a> &rarr;</li></ul></nav></footer></article><div class="post-entry"><div class="tile"><div id="disqus_thread"></div><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'https://blog.jle.im/entry/automatic-propagation-of-uncertainty-with-ad.html';
    this.page.identifier = 'uncertain';
};
(function() {
    var d = document, s = d.createElement('script');
    s.src = '//incode.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
})();
</script><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a><br></noscript><a href="http://disqus.com" class="dsq-brlink">Comments powered by <span class="logo-disqus">Disqus</span></a></div></div></div></div></div><div id="footer-container"><div id="footer-content"><div class="tile"><div class="footer-copyright">&copy; 2016 Justin Le</div><div class="footer-follow social-follows"><ul class="social-follows-list"><li><ul class="social-follows-list-social"><li><a class="social-follow-facebook" title="Friend me on Facebook!" href="https://facebook.com/mstksg">Facebook</a></li><li><a class="social-follow-twitter" title="Follow me on Twitter!" href="https://twitter.com/intent/user?user_id=mstk" onclick="window.open(
  &#39;http://twitter.com/intent/user?user_id=907281&#39;,
  &#39;facebook-share-dialog&#39;,
  &#39;width=550,height=520&#39;);
return false;
">Twitter</a></li><li><a class="social-follow-gplus" title="Add me on Google+!" href="https://plus.google.com/+JustinLe">Google+</a></li><li><a class="social-follow-linkedin" title="Connect with me on LinkedIn!" href="https://linkedin.com/in/lejustin">LinkedIn</a></li><li><a class="social-follow-github" title="Fork me on Github!" href="https://github.com/mstksg">Github</a></li><li><a class="social-follow-keybase" title="Track me on Keybase!" href="https://keybase.io/mstksg">Keybase</a></li><li><a class="social-follow-bitcoin" title="Donate via bitcoin!" href="https://coinbase.com/mstksg">Bitcoin</a></li></ul></li><li><ul class="social-follows-list-site"><li><a class="social-follow-rss" title="Subscribe to my RSS Feed!" href="http://feeds.feedburner.com/incodeblog">RSS</a></li><li><a class="social-follow-email" title="Subscribe to the mailing list!" href="https://feedburner.google.com/fb/a/mailverify?loc=en_US&amp;uri=incodeblog">Mailing list</a></li></ul></li></ul></div></div></div></div></body></html>